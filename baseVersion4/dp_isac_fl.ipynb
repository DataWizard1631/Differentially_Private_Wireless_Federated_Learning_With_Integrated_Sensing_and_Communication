{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2faff9ba",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b6c69",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "M           = 8                 # Number of clients\n",
    "A           = 10                # Local epochs\n",
    "G           = 100               # Global rounds\n",
    "bs          = 64                # Batch size\n",
    "lr          = 0.01              # Learning rate\n",
    "clip_C      = 1.0               # Clipping norm\n",
    "delta       = 1e-5              # DP Parameter δ\n",
    "eps_list    = [1, 2, 5, 10]     # Privacy budgets ε\n",
    "\n",
    "device      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cs = 1.0  # Sensing rate: samples/sec (for dataset growth plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926618c9",
   "metadata": {},
   "source": [
    "### Wireless / OFDMA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "K       = 16              # Subcarriers\n",
    "BW      = 80e6            # Total bandwidth (Hz)\n",
    "sigma2  = 10**(-169/10)   # Noise power density (W/Hz)\n",
    "Pmax    = 10**(-30/10)    # 10 dBm in Watts\n",
    "rs      = [2,4,6]         # bits per symbol\n",
    "beta1, beta2 = 0.2, -1.6  # BER constants\n",
    "d0, alpha = 1.0, 2.5      # path-loss reference & exponent\n",
    "Tsc     = 10.0            # ISAC slot duration (sec)\n",
    "a_m     = 0.5             # fraction for sensing/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367098a8",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87873eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b36b5f",
   "metadata": {},
   "source": [
    "### IID Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iid_loaders(dataset, M, bs):\n",
    "    idx = torch.randperm(len(dataset))\n",
    "    split = len(dataset) // M\n",
    "    loaders = []\n",
    "    for i in range(M):\n",
    "        part = idx[i*split:(i+1)*split]\n",
    "        loaders.append(DataLoader(Subset(dataset, part), batch_size=bs, shuffle=True))\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99207aba",
   "metadata": {},
   "source": [
    "### Wireless helper: generate SISO Rayleigh channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_channels(positions):\n",
    "    H = np.zeros((M,K), dtype=complex)\n",
    "    for m,(x,y) in enumerate(positions):\n",
    "        d = np.hypot(x,y) + 1e-6\n",
    "        pl = 10**(-30/10)*(d/d0)**(-alpha)\n",
    "        # Rayleigh: CN(0,pl)\n",
    "        h = np.sqrt(pl)*(np.random.randn(K)+1j*np.random.randn(K))/np.sqrt(2)\n",
    "        H[m] = h\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4022e91",
   "metadata": {},
   "source": [
    "### Pick one subcarrier & modulation, compute R and upload time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uplink(Hm, N_bits, a_m=a_m):\n",
    "    best = (0,None,0,0)\n",
    "    Tmax = (1 - a_m)*Tsc\n",
    "    sym_rate = BW/K\n",
    "    for k in range(K):\n",
    "        gain2 = abs(Hm[k])**2\n",
    "        for r in rs:\n",
    "            # required SNR threshold from BER <= 1e-5\n",
    "            SNR_th = (2*r-1)/(-beta2)*np.log(beta1/1e-5)\n",
    "            p_req = SNR_th * sigma2 / gain2\n",
    "            if p_req <= Pmax:\n",
    "                R = r * sym_rate\n",
    "                Tu = N_bits / R\n",
    "                if Tu <= Tmax and R>best[0]:\n",
    "                    best = (R,k,r,Tu)\n",
    "    return best  # (rate, subcarrier, bits/symbol, upload_time) or (0,None,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe124bc",
   "metadata": {},
   "source": [
    "### DP Clip & Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_clip_and_noise(client_model, global_model, eps, delta, clip_C, G, Dmin):\n",
    "    sensitivity = 2*clip_C / Dmin\n",
    "    sigma = (sensitivity * np.sqrt(2*G*np.log(1.25/delta))) / eps\n",
    "    g_state = global_model.state_dict()\n",
    "    c_state = client_model.state_dict()\n",
    "    new_state = {}\n",
    "    for k in g_state:\n",
    "        dw = c_state[k].to(device) - g_state[k].to(device)\n",
    "        norm = torch.norm(dw)\n",
    "        if norm > clip_C:\n",
    "            dw = dw * (clip_C/norm)\n",
    "        noise = torch.randn_like(dw)*sigma\n",
    "        new_state[k] = g_state[k].to(device) + dw + noise\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d02fea",
   "metadata": {},
   "source": [
    "### Server aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5837b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(states):\n",
    "    agg = {}\n",
    "    for k in states[0]:\n",
    "        agg[k] = sum([st[k] for st in states]) / len(states)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c769e3",
   "metadata": {},
   "source": [
    "### Train & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_train(model, loader, global_state):\n",
    "    model.load_state_dict(global_state)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(A):\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss_fn(logits,y).backward()\n",
    "            opt.step()\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    tot_l, corr, tot = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            tot_l += loss_fn(logits,y).item()\n",
    "            _,p = logits.max(1)\n",
    "            corr += (p==y).sum().item()\n",
    "            tot += y.size(0)\n",
    "    return tot_l/tot, corr/tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e59f22",
   "metadata": {},
   "source": [
    "### Main Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the full MNIST train set for sensing/growing\n",
    "full_train_ds = datasets.MNIST('.', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_ds  = datasets.MNIST('.',train=False,download=True,transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_ds,batch_size=bs,shuffle=False)\n",
    "\n",
    "N_bits = sum(p.numel() for p in SimpleMLP().parameters())*32  # model size in bits\n",
    "\n",
    "results = {}\n",
    "dataset_sizes = {eps: [[] for _ in range(M)] for eps in eps_list}\n",
    "upload_times = {eps: [[] for _ in range(M)] for eps in eps_list}\n",
    "allowed_times = {eps: [[] for _ in range(M)] for eps in eps_list}\n",
    "num_active_per_round = {eps: [] for eps in eps_list}\n",
    "upload_success_rate = {eps: [] for eps in eps_list}\n",
    "\n",
    "def run_one_round(global_state, global_model, client_seen, eps, rs, round_idx, dataset_sizes, upload_times, allowed_times):\n",
    "    # Sensing step: grow each client's dataset\n",
    "    num_new = int(a_m * (len(full_train_ds) / G))\n",
    "    for m in range(M):\n",
    "        unseen = set(range(len(full_train_ds))) - client_seen[m]\n",
    "        picks = set(random.sample(unseen, min(len(unseen), num_new)))\n",
    "        client_seen[m].update(picks)\n",
    "        dataset_sizes[m].append(len(client_seen[m]))\n",
    "\n",
    "    # Build current loaders for each client\n",
    "    current_loaders = [\n",
    "        DataLoader(Subset(full_train_ds, list(client_seen[m])), batch_size=bs, shuffle=True)\n",
    "        for m in range(M)\n",
    "    ]\n",
    "    Dmin = min(len(client_seen[m]) for m in range(M))\n",
    "\n",
    "    # 1) generate random positions & channels\n",
    "    positions = [(random.uniform(-250,250), random.uniform(-250,250)) for _ in range(M)]\n",
    "    H = gen_channels(positions)\n",
    "\n",
    "    # 2) local train + DP + check uplink feasibility\n",
    "    dp_states = []\n",
    "    active = 0\n",
    "    for m, loader in enumerate(current_loaders):\n",
    "        local = SimpleMLP().to(device)\n",
    "        local_train(local, loader, global_state)\n",
    "\n",
    "        R,k_sel,r_sel,Tu = compute_uplink(H[m], N_bits, a_m=a_m)\n",
    "        Tmax = (1 - a_m)*Tsc\n",
    "        upload_times[m].append(Tu)\n",
    "        allowed_times[m].append(Tmax)\n",
    "        if R>0:\n",
    "            active += 1\n",
    "            dp_states.append(dp_clip_and_noise(local, global_model,eps, delta, clip_C, G, Dmin))\n",
    "        # dataset_sizes already updated above\n",
    "\n",
    "    return dp_states, active, client_seen\n",
    "\n",
    "for eps in eps_list:\n",
    "    print(f\"=== ε={eps} ===\")\n",
    "    global_model = SimpleMLP().to(device)\n",
    "    global_state = global_model.state_dict()\n",
    "    loss_hist, acc_hist, active_frac = [],[],[]\n",
    "\n",
    "    # Initialize per-client seen indices (sensing memory)\n",
    "    client_seen = [set() for _ in range(M)]\n",
    "    # Initial random split (IID)\n",
    "    idx = torch.randperm(len(full_train_ds))\n",
    "    split = len(full_train_ds) // M\n",
    "    for m in range(M):\n",
    "        client_seen[m].update(idx[m*split:(m+1)*split].tolist())\n",
    "        dataset_sizes[eps][m].append(len(client_seen[m]))  # Ensure initial value is included\n",
    "\n",
    "    for rnd in range(1, G+1):\n",
    "        dp_states, active, client_seen = run_one_round(\n",
    "            global_state, global_model, client_seen, eps, rs, rnd, dataset_sizes[eps], upload_times[eps], allowed_times[eps]\n",
    "        )\n",
    "\n",
    "        num_active_per_round[eps].append(active)\n",
    "        upload_success_rate[eps].append(active/M)\n",
    "\n",
    "        # 3) aggregate only active ones\n",
    "        if dp_states:\n",
    "            agg = server_aggregate(dp_states)\n",
    "            global_state = agg\n",
    "            global_model.load_state_dict(global_state)\n",
    "\n",
    "        # 4) eval\n",
    "        l,a = evaluate(global_model, test_loader)\n",
    "        loss_hist.append(l); acc_hist.append(a)\n",
    "        active_frac.append(active/M)\n",
    "\n",
    "        if rnd%20==0:\n",
    "            print(f\" round {rnd:3d} | loss {l:.4f} acc {a:.3f} active {active}/{M}\")\n",
    "\n",
    "    results[eps] = (loss_hist,acc_hist,active_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf120a",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b88e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test Accuracy vs. Global Round\n",
    "plt.figure(figsize=(8,4))\n",
    "for eps in eps_list:\n",
    "    plt.plot(results[eps][1], label=f\"ε={eps}\")\n",
    "plt.title(\"Test Accuracy vs. Global Round\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2. Test Loss vs. Global Round\n",
    "plt.figure(figsize=(8,4))\n",
    "for eps in eps_list:\n",
    "    plt.plot(results[eps][0], label=f\"ε={eps}\")\n",
    "plt.title(\"Test Loss vs. Global Round\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. Number of Participating Clients per Round\n",
    "plt.figure(figsize=(8,4))\n",
    "for eps in eps_list:\n",
    "    plt.plot(num_active_per_round[eps], label=f\"ε={eps}\")\n",
    "plt.title(\"Number of Participating Clients per Round\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Active Clients\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. Dataset Size per Client vs. Round\n",
    "plt.figure(figsize=(10,5))\n",
    "for eps in eps_list:\n",
    "    for m in range(M):\n",
    "        plt.plot(dataset_sizes[eps][m], label=f\"Client {m+1} (ε={eps})\")\n",
    "plt.title(\"Dataset Size per Client vs. Round\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Dataset Size\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Upload Time vs. Allowed Time Budget (for client 0)\n",
    "plt.figure(figsize=(8,4))\n",
    "for eps in eps_list:\n",
    "    plt.plot(upload_times[eps][0], label=f\"Upload Time ε={eps}\")\n",
    "    plt.plot(allowed_times[eps][0], '--', label=f\"Allowed Time ε={eps}\")\n",
    "plt.title(\"Upload Time vs. Allowed Time Budget (Client 1)\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Time (sec)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6. Upload Success Rate vs. Round\n",
    "plt.figure(figsize=(8,4))\n",
    "for eps in eps_list:\n",
    "    plt.plot(upload_success_rate[eps], label=f\"ε={eps}\")\n",
    "plt.title(\"Upload Success Rate vs. Round\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Success Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218882b1",
   "metadata": {},
   "source": [
    "### Accuracy vs. Modulation Scheme\n",
    "Compare the final test accuracy for different allowed modulation schemes (`rs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs. Modulation Scheme\n",
    "mod_schemes = {\n",
    "    \"QPSK\": [2],\n",
    "    \"16QAM\": [4],\n",
    "    \"64QAM\": [6],\n",
    "    \"QPSK+16QAM\": [2,4],\n",
    "    \"All\": [2,4,6]\n",
    "}\n",
    "mod_acc = {}\n",
    "\n",
    "for name, rs_mod in mod_schemes.items():\n",
    "    # Set up experiment for this modulation scheme\n",
    "    rs = rs_mod\n",
    "    eps = 2  # Repeat only for one privacy level for clarity\n",
    "    global_model = SimpleMLP().to(device)\n",
    "    global_state = global_model.state_dict()\n",
    "    # Re-initialize per-client seen indices and dataset sizes\n",
    "    client_seen = [set() for _ in range(M)]\n",
    "    idx = torch.randperm(len(full_train_ds))\n",
    "    split = len(full_train_ds) // M\n",
    "    dataset_sizes_mod = [[] for _ in range(M)]\n",
    "    upload_times_mod = [[] for _ in range(M)]\n",
    "    allowed_times_mod = [[] for _ in range(M)]\n",
    "    for m in range(M):\n",
    "        client_seen[m].update(idx[m*split:(m+1)*split].tolist())\n",
    "        dataset_sizes_mod[m].append(len(client_seen[m]))\n",
    "    for rnd in range(1, G+1):\n",
    "        dp_states, active, client_seen = run_one_round(\n",
    "            global_state, global_model, client_seen, eps, rs, rnd, dataset_sizes_mod, upload_times_mod, allowed_times_mod\n",
    "        )\n",
    "        if dp_states:\n",
    "            agg = server_aggregate(dp_states)\n",
    "            global_state = agg\n",
    "            global_model.load_state_dict(global_state)\n",
    "    # Evaluate at the end\n",
    "    _, acc = evaluate(global_model, test_loader)\n",
    "    mod_acc[name] = acc\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(list(mod_acc.keys()), list(mod_acc.values()))\n",
    "plt.title(\"Final Test Accuracy vs. Modulation Scheme (ε=2)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Modulation Scheme\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
